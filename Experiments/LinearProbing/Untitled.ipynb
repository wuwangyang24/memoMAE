{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44c62de-7287-47cf-a068-4f46b3f086f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/memomae/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sagemaker-user/memoMAE/\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from Model.memoMAE import memoMAE\n",
    "from Experiments.utils import load_backbone_from_ckpt\n",
    "from Experiments.dataloader import ImagenetData\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b5157b-cd5e-4e44-8454-fa3fb25f2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "config_path = '/home/sagemaker-user/memoMAE/Configs/config_mae.yaml'\n",
    "ckpt_path = '/home/sagemaker-user/memoMAE/checkpoints/mae-ViT-B-Patch-16-MemoCap100000-NumSim5-NosimEpochs20/last.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e2a37e-0f36-4371-a1c1-75e426af7fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded memoMAE. Missing keys: []\n",
      "Unexpected keys: []\n"
     ]
    }
   ],
   "source": [
    "mae_baseline = load_backbone_from_ckpt(config_path=config_path,\n",
    "                                       ModelClass=memoMAE,\n",
    "                                       ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58003a18-cd73-4e0a-ac92-72a15ff2f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_baseline = mae_baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db15187d-2905-415a-b937-1054eff35ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImagenetData(train_txt='/home/sagemaker-user/memoMAE/Data/train.txt', \n",
    "                    val_txt='/home/sagemaker-user/memoMAE/Data/val.txt', \n",
    "                    root_dir='/home/sagemaker-user/memoMAE/Data/',\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2242dde-a6d9-4690-8119-22dc8a59502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = data.val_dataloader()\n",
    "train_loader = data.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f9ab12-d3f1-4011-8d37-cb07688eacb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1562/1562 [06:52<00:00,  3.79it/s]\n"
     ]
    }
   ],
   "source": [
    "memorize = True\n",
    "k = 5\n",
    "if memorize:\n",
    "    for _ in range(1):\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(train_loader):\n",
    "                mae_baseline.forward_encoder_memo(images.to(0), 0., 0, memorize=memorize, fill_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38fc95c-0f70-49d9-8d28-73ff3b58139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1562 [00:00<?, ?it/s]/home/sagemaker-user/.conda/envs/memomae/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  x.storage().data_ptr() + x.storage_offset() * 4)\n",
      "100%|██████████| 1562/1562 [18:23<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "LATENTS_TRAIN = []\n",
    "LABELS_TRAIN = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        latents = mae_baseline.forward_encoder_memo(images.to(0), 0., k, memorize=False)[0]\n",
    "        LATENTS_TRAIN.append(latents.mean(1).cpu())\n",
    "        LABELS_TRAIN.append(labels.to(torch.long).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac2159c1-d3f7-4bdd-94cd-5d09a81a3a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [06:24<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "LATENTS_VAL = []\n",
    "LABELS_VAL = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader):\n",
    "        latents = mae_baseline.forward_encoder_memo(images.to(0), 0., 5, memorize=True)[0]\n",
    "        LATENTS_VAL.append(latents.mean(1).cpu())\n",
    "        LABELS_VAL.append(labels.to(torch.long).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af247ccb-707c-468d-a119-25caff774161",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b0b2d88-b400-4cd2-9dc4-493542f8668a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:42<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2159428596496582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ----- 1. Stack features & labels -----\n",
    "feats_train = torch.cat(LATENTS_TRAIN, dim=0)   # (N, D)\n",
    "labels_train = torch.cat(LABELS_TRAIN, dim=0) # (N,)\n",
    "feats_test = torch.cat(LATENTS_VAL, dim=0)   # (N, D)\n",
    "labels_test = torch.cat(LABELS_VAL, dim=0) # (N,)\n",
    "N, D = feats_train.shape\n",
    "num_classes = int(labels_train.max().item()) + 1\n",
    "# move to device\n",
    "if device != 'cpu':\n",
    "    feats_train = feats_train.to(device)\n",
    "    labels_train = labels_train.to(device)\n",
    "    feats_test = feats_test.to(device)\n",
    "    labels_test = labels_test.to(device)\n",
    "# ----- 3. Linear classifier with BatchNorm -----\n",
    "clf = nn.Sequential(\n",
    "    nn.BatchNorm1d(D, affine=False),\n",
    "    nn.Linear(D, num_classes)\n",
    ").to(device)\n",
    "# MAE LR scaling rule\n",
    "batch_size = 2048\n",
    "batch_size = min(batch_size, feats_train.size(0))\n",
    "base_lr = 0.1\n",
    "max_lr = base_lr * batch_size / 256.0\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(feats_train, labels_train),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "optimizer = torch.optim.SGD(\n",
    "    clf.parameters(),\n",
    "    lr=max_lr,          # final LR, warmup scheduler will scale it\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0,\n",
    ")\n",
    "# ----- 4. Linear warmup + cosine schedulers -----\n",
    "warmup_epochs = 10\n",
    "total_epochs = 100\n",
    "scheduler_warmup = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=1e-6,       # start at near-zero LR\n",
    "    end_factor=1.0,          # warm up to max_lr\n",
    "    total_iters=warmup_epochs,\n",
    ")\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=total_epochs - warmup_epochs,\n",
    "    eta_min=1e-6,\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[scheduler_warmup, scheduler_cosine],\n",
    "    milestones=[warmup_epochs],\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# ----- 5. Training -----\n",
    "clf.train()\n",
    "with torch.enable_grad():\n",
    "    for epoch in tqdm(range(total_epochs)):\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = clf(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "# ----- 6. Evaluation -----\n",
    "clf.eval()\n",
    "with torch.no_grad():\n",
    "    preds = clf(feats_test).argmax(dim=1)\n",
    "    acc = (preds == labels_test).float().mean().item()\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018028e-7f37-41a1-bb59-6de81d66d47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0410f75-0e97-4c14-942c-2cdca4768308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15e17aea-626e-486f-91ff-d0fe13a3f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = 0.5870571136474609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a103c27-399c-4907-b41c-56cb0c0a1adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17acd28f-3c4c-4660-90f4-fb016153d1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (memomae)",
   "language": "python",
   "name": "memomae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
