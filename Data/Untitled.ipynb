{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f41420c6-ce52-4906-8aae-ac212f139575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 100\n",
      "Example mapping: [('n01440764', 0), ('n01443537', 1), ('n01484850', 2), ('n01491361', 3), ('n01494475', 4), ('n01496331', 5), ('n01498041', 6), ('n01514668', 7), ('n01514859', 8), ('n01531178', 9)]\n",
      "✔ train.txt, val.txt, and class_to_idx.json created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "root = \"imagenet100\"   # <<< CHANGE THIS ###\n",
    "\n",
    "train_folders = [\"train.X1\", \"train.X2\", \"train.X3\", \"train.X4\"]\n",
    "val_folder = \"val.X\"\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1 — Collect all class names\n",
    "# -------------------------------\n",
    "all_classes = set()\n",
    "\n",
    "# gather classes from train\n",
    "for split in train_folders:\n",
    "    split_path = os.path.join(root, split)\n",
    "    for cls in os.listdir(split_path):\n",
    "        if os.path.isdir(os.path.join(split_path, cls)):\n",
    "            all_classes.add(cls)\n",
    "\n",
    "# gather classes from val\n",
    "val_path = os.path.join(root, val_folder)\n",
    "for cls in os.listdir(val_path):\n",
    "    if os.path.isdir(os.path.join(val_path, cls)):\n",
    "        all_classes.add(cls)\n",
    "\n",
    "# sort + create mapping {class_string: index}\n",
    "all_classes = sorted(list(all_classes))\n",
    "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(all_classes)}\n",
    "\n",
    "print(\"Total classes:\", len(class_to_idx))\n",
    "print(\"Example mapping:\", list(class_to_idx.items())[:10])\n",
    "\n",
    "# Save mapping to json\n",
    "with open(\"class_to_idx.json\", \"w\") as f:\n",
    "    json.dump(class_to_idx, f, indent=4)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2 — Write train.txt\n",
    "# -------------------------------\n",
    "with open(\"train.txt\", \"w\") as train_txt:\n",
    "    for split in train_folders:\n",
    "        split_path = os.path.join(root, split)\n",
    "\n",
    "        for cls_name in sorted(os.listdir(split_path)):\n",
    "            cls_path = os.path.join(split_path, cls_name)\n",
    "            if not os.path.isdir(cls_path):\n",
    "                continue\n",
    "\n",
    "            label = class_to_idx[cls_name]\n",
    "\n",
    "            for fname in os.listdir(cls_path):\n",
    "                fpath = os.path.join(cls_path, fname)\n",
    "                if os.path.isfile(fpath):\n",
    "                    train_txt.write(f\"{fpath} {label}\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3 — Write val.txt\n",
    "# -------------------------------\n",
    "with open(\"val.txt\", \"w\") as val_txt:\n",
    "    for cls_name in sorted(os.listdir(val_path)):\n",
    "        cls_path = os.path.join(val_path, cls_name)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "\n",
    "        label = class_to_idx[cls_name]\n",
    "\n",
    "        for fname in os.listdir(cls_path):\n",
    "            fpath = os.path.join(cls_path, fname)\n",
    "            if os.path.isfile(fpath):\n",
    "                val_txt.write(f\"{fpath} {label}\\n\")\n",
    "\n",
    "print(\"✔ train.txt, val.txt, and class_to_idx.json created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d300fd6b-b088-48e1-8a3f-92c61efbc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 classes in train.txt\n",
      "Class 0: selected 100 samples to move/add to val\n",
      "Class 2: selected 100 samples to move/add to val\n",
      "Class 4: selected 100 samples to move/add to val\n",
      "Class 9: selected 100 samples to move/add to val\n",
      "Class 20: selected 100 samples to move/add to val\n",
      "Class 23: selected 100 samples to move/add to val\n",
      "Class 29: selected 100 samples to move/add to val\n",
      "Class 31: selected 100 samples to move/add to val\n",
      "Class 41: selected 100 samples to move/add to val\n",
      "Class 53: selected 100 samples to move/add to val\n",
      "Class 55: selected 100 samples to move/add to val\n",
      "Class 59: selected 100 samples to move/add to val\n",
      "Class 61: selected 100 samples to move/add to val\n",
      "Class 62: selected 100 samples to move/add to val\n",
      "Class 65: selected 100 samples to move/add to val\n",
      "Class 73: selected 100 samples to move/add to val\n",
      "Class 74: selected 100 samples to move/add to val\n",
      "Class 75: selected 100 samples to move/add to val\n",
      "Class 78: selected 100 samples to move/add to val\n",
      "Class 82: selected 100 samples to move/add to val\n",
      "Class 83: selected 100 samples to move/add to val\n",
      "Class 88: selected 100 samples to move/add to val\n",
      "Class 90: selected 100 samples to move/add to val\n",
      "Class 93: selected 100 samples to move/add to val\n",
      "Class 96: selected 100 samples to move/add to val\n",
      "Class 1: selected 100 samples to move/add to val\n",
      "Class 7: selected 100 samples to move/add to val\n",
      "Class 8: selected 100 samples to move/add to val\n",
      "Class 10: selected 100 samples to move/add to val\n",
      "Class 13: selected 100 samples to move/add to val\n",
      "Class 15: selected 100 samples to move/add to val\n",
      "Class 27: selected 100 samples to move/add to val\n",
      "Class 32: selected 100 samples to move/add to val\n",
      "Class 33: selected 100 samples to move/add to val\n",
      "Class 35: selected 100 samples to move/add to val\n",
      "Class 37: selected 100 samples to move/add to val\n",
      "Class 39: selected 100 samples to move/add to val\n",
      "Class 43: selected 100 samples to move/add to val\n",
      "Class 46: selected 100 samples to move/add to val\n",
      "Class 48: selected 100 samples to move/add to val\n",
      "Class 49: selected 100 samples to move/add to val\n",
      "Class 50: selected 100 samples to move/add to val\n",
      "Class 51: selected 100 samples to move/add to val\n",
      "Class 66: selected 100 samples to move/add to val\n",
      "Class 79: selected 100 samples to move/add to val\n",
      "Class 92: selected 100 samples to move/add to val\n",
      "Class 94: selected 100 samples to move/add to val\n",
      "Class 95: selected 100 samples to move/add to val\n",
      "Class 98: selected 100 samples to move/add to val\n",
      "Class 99: selected 100 samples to move/add to val\n",
      "Class 6: selected 100 samples to move/add to val\n",
      "Class 11: selected 100 samples to move/add to val\n",
      "Class 12: selected 100 samples to move/add to val\n",
      "Class 14: selected 100 samples to move/add to val\n",
      "Class 16: selected 100 samples to move/add to val\n",
      "Class 17: selected 100 samples to move/add to val\n",
      "Class 19: selected 100 samples to move/add to val\n",
      "Class 21: selected 100 samples to move/add to val\n",
      "Class 22: selected 100 samples to move/add to val\n",
      "Class 24: selected 100 samples to move/add to val\n",
      "Class 28: selected 100 samples to move/add to val\n",
      "Class 30: selected 100 samples to move/add to val\n",
      "Class 36: selected 100 samples to move/add to val\n",
      "Class 42: selected 100 samples to move/add to val\n",
      "Class 45: selected 100 samples to move/add to val\n",
      "Class 63: selected 100 samples to move/add to val\n",
      "Class 64: selected 100 samples to move/add to val\n",
      "Class 67: selected 100 samples to move/add to val\n",
      "Class 71: selected 100 samples to move/add to val\n",
      "Class 77: selected 100 samples to move/add to val\n",
      "Class 80: selected 100 samples to move/add to val\n",
      "Class 86: selected 100 samples to move/add to val\n",
      "Class 87: selected 100 samples to move/add to val\n",
      "Class 89: selected 100 samples to move/add to val\n",
      "Class 91: selected 100 samples to move/add to val\n",
      "Class 3: selected 100 samples to move/add to val\n",
      "Class 5: selected 100 samples to move/add to val\n",
      "Class 18: selected 100 samples to move/add to val\n",
      "Class 25: selected 100 samples to move/add to val\n",
      "Class 26: selected 100 samples to move/add to val\n",
      "Class 34: selected 100 samples to move/add to val\n",
      "Class 38: selected 100 samples to move/add to val\n",
      "Class 40: selected 100 samples to move/add to val\n",
      "Class 44: selected 100 samples to move/add to val\n",
      "Class 47: selected 100 samples to move/add to val\n",
      "Class 52: selected 100 samples to move/add to val\n",
      "Class 54: selected 100 samples to move/add to val\n",
      "Class 56: selected 100 samples to move/add to val\n",
      "Class 57: selected 100 samples to move/add to val\n",
      "Class 58: selected 100 samples to move/add to val\n",
      "Class 60: selected 100 samples to move/add to val\n",
      "Class 68: selected 100 samples to move/add to val\n",
      "Class 69: selected 100 samples to move/add to val\n",
      "Class 70: selected 100 samples to move/add to val\n",
      "Class 72: selected 100 samples to move/add to val\n",
      "Class 76: selected 100 samples to move/add to val\n",
      "Class 81: selected 100 samples to move/add to val\n",
      "Class 84: selected 100 samples to move/add to val\n",
      "Class 85: selected 100 samples to move/add to val\n",
      "Class 97: selected 100 samples to move/add to val\n",
      "Done!\n",
      "Original train: 130000 lines\n",
      "New train:      120000 lines\n",
      "Original val:   5000 lines\n",
      "New val:        15000 lines\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "TRAIN_TXT = \"train.txt\"\n",
    "VAL_TXT = \"val.txt\"\n",
    "NEW_TRAIN_TXT = \"train_new.txt\"\n",
    "NEW_VAL_TXT = \"val_new.txt\"\n",
    "\n",
    "SAMPLES_PER_CLASS = 100\n",
    "RANDOM_SEED = 42\n",
    "MOVE_INSTEAD_OF_DUPLICATE = True  # set False if you want to KEEP them in train as well\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Read existing train & val\n",
    "# -----------------------------\n",
    "with open(TRAIN_TXT, \"r\") as f:\n",
    "    train_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "with open(VAL_TXT, \"r\") as f:\n",
    "    val_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Parse train into (path, label)\n",
    "train_entries = []\n",
    "for line in train_lines:\n",
    "    # Split from the right in case path ever has spaces\n",
    "    path, label = line.rsplit(\" \", 1)\n",
    "    train_entries.append((path, label))\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2. Group train entries by class/label\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "by_class = defaultdict(list)  # label -> list of indices in train_entries\n",
    "\n",
    "for idx, (path, label) in enumerate(train_entries):\n",
    "    by_class[label].append(idx)\n",
    "\n",
    "print(f\"Found {len(by_class)} classes in train.txt\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3. Sample up to 300 per class from train\n",
    "# ---------------------------------------\n",
    "selected_indices = set()\n",
    "selected_lines_for_val = []\n",
    "\n",
    "for label, indices in by_class.items():\n",
    "    if len(indices) == 0:\n",
    "        continue\n",
    "\n",
    "    n_samples = min(SAMPLES_PER_CLASS, len(indices))\n",
    "    sampled = random.sample(indices, n_samples)\n",
    "\n",
    "    for idx in sampled:\n",
    "        path, lbl = train_entries[idx]\n",
    "        selected_lines_for_val.append(f\"{path} {lbl}\")\n",
    "        selected_indices.add(idx)\n",
    "\n",
    "    print(f\"Class {label}: selected {n_samples} samples to move/add to val\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4. Build new train and val lists\n",
    "# ---------------------------------------\n",
    "\n",
    "# Option A: move them (remove from train)\n",
    "if MOVE_INSTEAD_OF_DUPLICATE:\n",
    "    new_train_lines = [\n",
    "        f\"{path} {label}\"\n",
    "        for i, (path, label) in enumerate(train_entries)\n",
    "        if i not in selected_indices\n",
    "    ]\n",
    "else:\n",
    "    # Option B: keep all original train entries\n",
    "    new_train_lines = [f\"{path} {label}\" for (path, label) in train_entries]\n",
    "\n",
    "# New val = old val + new sampled ones\n",
    "new_val_lines = val_lines + selected_lines_for_val\n",
    "\n",
    "# ---------------------------------------\n",
    "# 5. Write out new files\n",
    "# ---------------------------------------\n",
    "with open(NEW_TRAIN_TXT, \"w\") as f:\n",
    "    for line in new_train_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "with open(NEW_VAL_TXT, \"w\") as f:\n",
    "    for line in new_val_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Done!\")\n",
    "print(f\"Original train: {len(train_lines)} lines\")\n",
    "print(f\"New train:      {len(new_train_lines)} lines\")\n",
    "print(f\"Original val:   {len(val_lines)} lines\")\n",
    "print(f\"New val:        {len(new_val_lines)} lines\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9ab39b-ad15-471e-a7ca-a05fb04cca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1200 images\n",
      "Class 1: 1200 images\n",
      "Class 2: 1200 images\n",
      "Class 3: 1200 images\n",
      "Class 4: 1200 images\n",
      "Class 5: 1200 images\n",
      "Class 6: 1200 images\n",
      "Class 7: 1200 images\n",
      "Class 8: 1200 images\n",
      "Class 9: 1200 images\n",
      "Class 10: 1200 images\n",
      "Class 11: 1200 images\n",
      "Class 12: 1200 images\n",
      "Class 13: 1200 images\n",
      "Class 14: 1200 images\n",
      "Class 15: 1200 images\n",
      "Class 16: 1200 images\n",
      "Class 17: 1200 images\n",
      "Class 18: 1200 images\n",
      "Class 19: 1200 images\n",
      "Class 20: 1200 images\n",
      "Class 21: 1200 images\n",
      "Class 22: 1200 images\n",
      "Class 23: 1200 images\n",
      "Class 24: 1200 images\n",
      "Class 25: 1200 images\n",
      "Class 26: 1200 images\n",
      "Class 27: 1200 images\n",
      "Class 28: 1200 images\n",
      "Class 29: 1200 images\n",
      "Class 30: 1200 images\n",
      "Class 31: 1200 images\n",
      "Class 32: 1200 images\n",
      "Class 33: 1200 images\n",
      "Class 34: 1200 images\n",
      "Class 35: 1200 images\n",
      "Class 36: 1200 images\n",
      "Class 37: 1200 images\n",
      "Class 38: 1200 images\n",
      "Class 39: 1200 images\n",
      "Class 40: 1200 images\n",
      "Class 41: 1200 images\n",
      "Class 42: 1200 images\n",
      "Class 43: 1200 images\n",
      "Class 44: 1200 images\n",
      "Class 45: 1200 images\n",
      "Class 46: 1200 images\n",
      "Class 47: 1200 images\n",
      "Class 48: 1200 images\n",
      "Class 49: 1200 images\n",
      "Class 50: 1200 images\n",
      "Class 51: 1200 images\n",
      "Class 52: 1200 images\n",
      "Class 53: 1200 images\n",
      "Class 54: 1200 images\n",
      "Class 55: 1200 images\n",
      "Class 56: 1200 images\n",
      "Class 57: 1200 images\n",
      "Class 58: 1200 images\n",
      "Class 59: 1200 images\n",
      "Class 60: 1200 images\n",
      "Class 61: 1200 images\n",
      "Class 62: 1200 images\n",
      "Class 63: 1200 images\n",
      "Class 64: 1200 images\n",
      "Class 65: 1200 images\n",
      "Class 66: 1200 images\n",
      "Class 67: 1200 images\n",
      "Class 68: 1200 images\n",
      "Class 69: 1200 images\n",
      "Class 70: 1200 images\n",
      "Class 71: 1200 images\n",
      "Class 72: 1200 images\n",
      "Class 73: 1200 images\n",
      "Class 74: 1200 images\n",
      "Class 75: 1200 images\n",
      "Class 76: 1200 images\n",
      "Class 77: 1200 images\n",
      "Class 78: 1200 images\n",
      "Class 79: 1200 images\n",
      "Class 80: 1200 images\n",
      "Class 81: 1200 images\n",
      "Class 82: 1200 images\n",
      "Class 83: 1200 images\n",
      "Class 84: 1200 images\n",
      "Class 85: 1200 images\n",
      "Class 86: 1200 images\n",
      "Class 87: 1200 images\n",
      "Class 88: 1200 images\n",
      "Class 89: 1200 images\n",
      "Class 90: 1200 images\n",
      "Class 91: 1200 images\n",
      "Class 92: 1200 images\n",
      "Class 93: 1200 images\n",
      "Class 94: 1200 images\n",
      "Class 95: 1200 images\n",
      "Class 96: 1200 images\n",
      "Class 97: 1200 images\n",
      "Class 98: 1200 images\n",
      "Class 99: 1200 images\n",
      "\n",
      "All classes have 1000 images?: False\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "train_file = \"train.txt\"\n",
    "\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "with open(train_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        path, label = line.strip().rsplit(\" \", 1)\n",
    "        class_counts[label] += 1\n",
    "\n",
    "# Print counts\n",
    "for label in sorted(class_counts.keys(), key=lambda x: int(x)):\n",
    "    print(f\"Class {label}: {class_counts[label]} images\")\n",
    "\n",
    "# Check if all equal to 1000\n",
    "all_ok = all(count == 1000 for count in class_counts.values())\n",
    "\n",
    "print(\"\\nAll classes have 1000 images?:\", all_ok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234ee67c-fb52-451d-bc94-6bcc2df206f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Shuffled train.txt → train_shuffled.txt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "inp = \"val.txt\"\n",
    "out = \"val_shuffled.txt\"\n",
    "\n",
    "with open(inp, \"r\") as f:\n",
    "    lines = [line for line in f if line.strip()]\n",
    "\n",
    "random.shuffle(lines)\n",
    "\n",
    "with open(out, \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "\n",
    "print(\"✔ Shuffled train.txt → train_shuffled.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf479d-8278-41a3-bd03-fc4b3f482b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f810a622-a597-4b0e-bbe5-047a42e2551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 100000\n",
      "Expanded length: 1000000\n",
      "Saved to: train_expanded.txt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "in_file = \"train.txt\"\n",
    "out_file = \"train_expanded.txt\"\n",
    "factor = 10    # expand to 10× size\n",
    "\n",
    "# Read original lines\n",
    "with open(in_file, \"r\") as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "orig_len = len(lines)\n",
    "target_len = orig_len * factor\n",
    "\n",
    "# Random sampling with replacement\n",
    "expanded = [random.choice(lines) for _ in range(target_len)]\n",
    "\n",
    "# Write new file\n",
    "with open(out_file, \"w\") as f:\n",
    "    f.write(\"\\n\".join(expanded))\n",
    "\n",
    "print(f\"Original length: {orig_len}\")\n",
    "print(f\"Expanded length: {len(expanded)}\")\n",
    "print(f\"Saved to: {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec9fbc-d7c3-4af2-92c3-e89196a274d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01086fde-dc9e-4584-b41e-d6183fc68eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc4bbd7-f71f-4699-9e94-888c6c582b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Saved to val_shuffled.txt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "input_file = \"val.txt\"\n",
    "output_file = \"val_shuffled.txt\"\n",
    "\n",
    "lines = []\n",
    "with open(input_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        path, cls = line.strip().split()\n",
    "        # remove the first part of the path (everything before first '/')\n",
    "        new_path = path.split('/', 1)[1]\n",
    "        lines.append(f\"{new_path} {cls}\\n\")\n",
    "\n",
    "# shuffle lines\n",
    "random.shuffle(lines)\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "\n",
    "print(\"Done! Saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87aa1f-9102-41ba-be65-2f9396195493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (memomae)",
   "language": "python",
   "name": "memomae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
