{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2f90140-9e32-4da6-871b-8138a55aa36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2af98f99-73e3-4dd0-b030-f7d2c75dda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, H, N, D, M = 8, 4, 12, 128, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a70115e-726e-4fb3-9dd9-16d4a088e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dh = D//H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb62f55d-760e-4562-a42c-cf5230ac548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.rand(B, N, D)\n",
    "k_x = torch.rand(B, N, D)\n",
    "v_x = torch.rand(B, N, D)\n",
    "k_sim = torch.rand(B, N, M, D)\n",
    "v_sim = torch.rand(B, N, M, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b78200a-69bc-4541-865a-a1ef37b57d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.cat([k_x.unsqueeze(1).expand(-1, N, -1, -1), k_sim], dim=2)  # (B, N, N+M, D)\n",
    "v = torch.cat([v_x.unsqueeze(1).expand(-1, N, -1, -1), v_sim], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c9faac3-3b93-4465-b0f7-b1e42a46750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = torch.matmul(q.unsqueeze(2), k.transpose(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6657994-08d6-4fdd-9ba3-670ed8c79c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = attn.squeeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3d34563-84b4-4e6f-abd7-b8d3b45f7243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 12, 17])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dcd422-7492-48a4-b5f2-8dc687da65ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3aa40431-184d-4720-92f5-e2045439eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-part: (B, H, N, Dh) x (B, H, Dh, N) → (B, H, N, N)\n",
    "logits_self = torch.matmul(q, k_x.transpose(-2, -1))\n",
    "# sim-part (per n): inner product of q[..., n, :] with each of its M neighbors\n",
    "# q:     (B, H, N,   1, Dh)\n",
    "# k_sim: (B, H, N,   M, Dh)\n",
    "logits_sim = (q.unsqueeze(2) * k_sim).sum(dim=-1)  # (B, H, N, M)\n",
    "# Combine: (B, H, N, N+M)\n",
    "logits = torch.cat([logits_self, logits_sim], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a80b275-18e1-4026-a929-380fd07ea302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 12, 17])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ba2a1d-9205-41fa-87f6-38ef3b2ead67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a3513-9aab-4c66-aa69-0193d7f11ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbaff18-de75-4517-9127-4b69fc0f3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N, D = x.shape\n",
    "_, _, M, _ = sim_embeddings.shape\n",
    "H = self.num_heads\n",
    "Dh = D // H\n",
    "\n",
    "# ---- 1. Project Q ----\n",
    "q = self.q(x).view(B, N, H, Dh).permute(0, 2, 1, 3)        # (B, H, N, Dh)\n",
    "\n",
    "# ---- 2. K, V for self patches ----\n",
    "kv_x = self.kv(x)                                          # (B, N, 2D)\n",
    "k_x, v_x = kv_x.chunk(2, dim=-1)                           # (B, N, D), (B, N, D)\n",
    "k_x = k_x.view(B, N, H, Dh).permute(0, 2, 1, 3)            # (B, H, N, Dh)\n",
    "v_x = v_x.view(B, N, H, Dh).permute(0, 2, 1, 3)            # (B, H, N, Dh)\n",
    "\n",
    "# ---- 3. K, V for similar patches (per query) ----\n",
    "kv_sim = self.kv(sim_embeddings)                           # (B, N, M, 2D)\n",
    "k_sim, v_sim = kv_sim.chunk(2, dim=-1)                     # (B, N, M, D)\n",
    "k_sim = k_sim.view(B, N, M, H, Dh).permute(0, 3, 1, 2, 4)  # (B, H, N, M, Dh)\n",
    "v_sim = v_sim.view(B, N, M, H, Dh).permute(0, 3, 1, 2, 4)  # (B, H, N, M, Dh)\n",
    "\n",
    "# ---- 4. Attention logits ----\n",
    "# self-part: (B, H, N, Dh) x (B, H, Dh, N) → (B, H, N, N)\n",
    "logits_self = torch.matmul(q, k_x.transpose(-2, -1)) * self.scale\n",
    "\n",
    "# sim-part (per n): inner product of q[..., n, :] with each of its M neighbors\n",
    "# q:     (B, H, N,   1, Dh)\n",
    "# k_sim: (B, H, N,   M, Dh)\n",
    "logits_sim = (q.unsqueeze(3) * k_sim).sum(dim=-1) * self.scale  # (B, H, N, M)\n",
    "\n",
    "# Combine: (B, H, N, N+M)\n",
    "logits = torch.cat([logits_self, logits_sim], dim=-1)\n",
    "\n",
    "# ---- 5. Softmax over all N+M keys ----\n",
    "attn = logits.softmax(dim=-1)\n",
    "attn = self.attn_drop(attn)                                # (B, H, N, N+M)\n",
    "\n",
    "# Split back\n",
    "attn_self = attn[..., :N]                                  # (B, H, N, N)\n",
    "attn_sim  = attn[..., N:]                                  # (B, H, N, M)\n",
    "\n",
    "# ---- 6. Weighted sum for values ----\n",
    "# self values: (B, H, N, Dh), attn_self: (B, H, N, N)\n",
    "out_self = torch.matmul(attn_self, v_x)                    # (B, H, N, Dh)\n",
    "\n",
    "# sim values: per n, weights over its M neighbors\n",
    "# attn_sim: (B, H, N, M) → (B, H, N, M, 1)\n",
    "out_sim = (attn_sim.unsqueeze(-1) * v_sim).sum(dim=3)      # (B, H, N, Dh)\n",
    "\n",
    "# total output per query\n",
    "out = out_self + out_sim                                   # (B, H, N, Dh)\n",
    "\n",
    "# merge heads back to (B, N, D)\n",
    "out = out.permute(0, 2, 1, 3).reshape(B, N, D)\n",
    "out = self.proj(out)\n",
    "out = self.proj_drop(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (memomae)",
   "language": "python",
   "name": "memomae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
