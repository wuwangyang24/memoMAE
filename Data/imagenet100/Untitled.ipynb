{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "310fd50d-3243-4f39-822d-579804c4614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 classes in train.txt\n",
      "Class 0: selected 300 samples to move/add to val\n",
      "Class 2: selected 300 samples to move/add to val\n",
      "Class 4: selected 300 samples to move/add to val\n",
      "Class 9: selected 300 samples to move/add to val\n",
      "Class 20: selected 300 samples to move/add to val\n",
      "Class 23: selected 300 samples to move/add to val\n",
      "Class 29: selected 300 samples to move/add to val\n",
      "Class 31: selected 300 samples to move/add to val\n",
      "Class 41: selected 300 samples to move/add to val\n",
      "Class 53: selected 300 samples to move/add to val\n",
      "Class 55: selected 300 samples to move/add to val\n",
      "Class 59: selected 300 samples to move/add to val\n",
      "Class 61: selected 300 samples to move/add to val\n",
      "Class 62: selected 300 samples to move/add to val\n",
      "Class 65: selected 300 samples to move/add to val\n",
      "Class 73: selected 300 samples to move/add to val\n",
      "Class 74: selected 300 samples to move/add to val\n",
      "Class 75: selected 300 samples to move/add to val\n",
      "Class 78: selected 300 samples to move/add to val\n",
      "Class 82: selected 300 samples to move/add to val\n",
      "Class 83: selected 300 samples to move/add to val\n",
      "Class 88: selected 300 samples to move/add to val\n",
      "Class 90: selected 300 samples to move/add to val\n",
      "Class 93: selected 300 samples to move/add to val\n",
      "Class 96: selected 300 samples to move/add to val\n",
      "Class 1: selected 300 samples to move/add to val\n",
      "Class 7: selected 300 samples to move/add to val\n",
      "Class 8: selected 300 samples to move/add to val\n",
      "Class 10: selected 300 samples to move/add to val\n",
      "Class 13: selected 300 samples to move/add to val\n",
      "Class 15: selected 300 samples to move/add to val\n",
      "Class 27: selected 300 samples to move/add to val\n",
      "Class 32: selected 300 samples to move/add to val\n",
      "Class 33: selected 300 samples to move/add to val\n",
      "Class 35: selected 300 samples to move/add to val\n",
      "Class 37: selected 300 samples to move/add to val\n",
      "Class 39: selected 300 samples to move/add to val\n",
      "Class 43: selected 300 samples to move/add to val\n",
      "Class 46: selected 300 samples to move/add to val\n",
      "Class 48: selected 300 samples to move/add to val\n",
      "Class 49: selected 300 samples to move/add to val\n",
      "Class 50: selected 300 samples to move/add to val\n",
      "Class 51: selected 300 samples to move/add to val\n",
      "Class 66: selected 300 samples to move/add to val\n",
      "Class 79: selected 300 samples to move/add to val\n",
      "Class 92: selected 300 samples to move/add to val\n",
      "Class 94: selected 300 samples to move/add to val\n",
      "Class 95: selected 300 samples to move/add to val\n",
      "Class 98: selected 300 samples to move/add to val\n",
      "Class 99: selected 300 samples to move/add to val\n",
      "Class 6: selected 300 samples to move/add to val\n",
      "Class 11: selected 300 samples to move/add to val\n",
      "Class 12: selected 300 samples to move/add to val\n",
      "Class 14: selected 300 samples to move/add to val\n",
      "Class 16: selected 300 samples to move/add to val\n",
      "Class 17: selected 300 samples to move/add to val\n",
      "Class 19: selected 300 samples to move/add to val\n",
      "Class 21: selected 300 samples to move/add to val\n",
      "Class 22: selected 300 samples to move/add to val\n",
      "Class 24: selected 300 samples to move/add to val\n",
      "Class 28: selected 300 samples to move/add to val\n",
      "Class 30: selected 300 samples to move/add to val\n",
      "Class 36: selected 300 samples to move/add to val\n",
      "Class 42: selected 300 samples to move/add to val\n",
      "Class 45: selected 300 samples to move/add to val\n",
      "Class 63: selected 300 samples to move/add to val\n",
      "Class 64: selected 300 samples to move/add to val\n",
      "Class 67: selected 300 samples to move/add to val\n",
      "Class 71: selected 300 samples to move/add to val\n",
      "Class 77: selected 300 samples to move/add to val\n",
      "Class 80: selected 300 samples to move/add to val\n",
      "Class 86: selected 300 samples to move/add to val\n",
      "Class 87: selected 300 samples to move/add to val\n",
      "Class 89: selected 300 samples to move/add to val\n",
      "Class 91: selected 300 samples to move/add to val\n",
      "Class 3: selected 300 samples to move/add to val\n",
      "Class 5: selected 300 samples to move/add to val\n",
      "Class 18: selected 300 samples to move/add to val\n",
      "Class 25: selected 300 samples to move/add to val\n",
      "Class 26: selected 300 samples to move/add to val\n",
      "Class 34: selected 300 samples to move/add to val\n",
      "Class 38: selected 300 samples to move/add to val\n",
      "Class 40: selected 300 samples to move/add to val\n",
      "Class 44: selected 300 samples to move/add to val\n",
      "Class 47: selected 300 samples to move/add to val\n",
      "Class 52: selected 300 samples to move/add to val\n",
      "Class 54: selected 300 samples to move/add to val\n",
      "Class 56: selected 300 samples to move/add to val\n",
      "Class 57: selected 300 samples to move/add to val\n",
      "Class 58: selected 300 samples to move/add to val\n",
      "Class 60: selected 300 samples to move/add to val\n",
      "Class 68: selected 300 samples to move/add to val\n",
      "Class 69: selected 300 samples to move/add to val\n",
      "Class 70: selected 300 samples to move/add to val\n",
      "Class 72: selected 300 samples to move/add to val\n",
      "Class 76: selected 300 samples to move/add to val\n",
      "Class 81: selected 300 samples to move/add to val\n",
      "Class 84: selected 300 samples to move/add to val\n",
      "Class 85: selected 300 samples to move/add to val\n",
      "Class 97: selected 300 samples to move/add to val\n",
      "Done!\n",
      "Original train: 130000 lines\n",
      "New train:      100000 lines\n",
      "Original val:   5000 lines\n",
      "New val:        35000 lines\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "TRAIN_TXT = \"train.txt\"\n",
    "VAL_TXT = \"val.txt\"\n",
    "NEW_TRAIN_TXT = \"train_new.txt\"\n",
    "NEW_VAL_TXT = \"val_new.txt\"\n",
    "\n",
    "SAMPLES_PER_CLASS = 300\n",
    "RANDOM_SEED = 42\n",
    "MOVE_INSTEAD_OF_DUPLICATE = True  # set False if you want to KEEP them in train as well\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Read existing train & val\n",
    "# -----------------------------\n",
    "with open(TRAIN_TXT, \"r\") as f:\n",
    "    train_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "with open(VAL_TXT, \"r\") as f:\n",
    "    val_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Parse train into (path, label)\n",
    "train_entries = []\n",
    "for line in train_lines:\n",
    "    # Split from the right in case path ever has spaces\n",
    "    path, label = line.rsplit(\" \", 1)\n",
    "    train_entries.append((path, label))\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2. Group train entries by class/label\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "by_class = defaultdict(list)  # label -> list of indices in train_entries\n",
    "\n",
    "for idx, (path, label) in enumerate(train_entries):\n",
    "    by_class[label].append(idx)\n",
    "\n",
    "print(f\"Found {len(by_class)} classes in train.txt\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3. Sample up to 300 per class from train\n",
    "# ---------------------------------------\n",
    "selected_indices = set()\n",
    "selected_lines_for_val = []\n",
    "\n",
    "for label, indices in by_class.items():\n",
    "    if len(indices) == 0:\n",
    "        continue\n",
    "\n",
    "    n_samples = min(SAMPLES_PER_CLASS, len(indices))\n",
    "    sampled = random.sample(indices, n_samples)\n",
    "\n",
    "    for idx in sampled:\n",
    "        path, lbl = train_entries[idx]\n",
    "        selected_lines_for_val.append(f\"{path} {lbl}\")\n",
    "        selected_indices.add(idx)\n",
    "\n",
    "    print(f\"Class {label}: selected {n_samples} samples to move/add to val\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4. Build new train and val lists\n",
    "# ---------------------------------------\n",
    "\n",
    "# Option A: move them (remove from train)\n",
    "if MOVE_INSTEAD_OF_DUPLICATE:\n",
    "    new_train_lines = [\n",
    "        f\"{path} {label}\"\n",
    "        for i, (path, label) in enumerate(train_entries)\n",
    "        if i not in selected_indices\n",
    "    ]\n",
    "else:\n",
    "    # Option B: keep all original train entries\n",
    "    new_train_lines = [f\"{path} {label}\" for (path, label) in train_entries]\n",
    "\n",
    "# New val = old val + new sampled ones\n",
    "new_val_lines = val_lines + selected_lines_for_val\n",
    "\n",
    "# ---------------------------------------\n",
    "# 5. Write out new files\n",
    "# ---------------------------------------\n",
    "with open(NEW_TRAIN_TXT, \"w\") as f:\n",
    "    for line in new_train_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "with open(NEW_VAL_TXT, \"w\") as f:\n",
    "    for line in new_val_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Done!\")\n",
    "print(f\"Original train: {len(train_lines)} lines\")\n",
    "print(f\"New train:      {len(new_train_lines)} lines\")\n",
    "print(f\"Original val:   {len(val_lines)} lines\")\n",
    "print(f\"New val:        {len(new_val_lines)} lines\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9336cc7c-2019-40a8-8019-6b15212e36d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 350 images\n",
      "Class 1: 350 images\n",
      "Class 2: 350 images\n",
      "Class 3: 350 images\n",
      "Class 4: 350 images\n",
      "Class 5: 350 images\n",
      "Class 6: 350 images\n",
      "Class 7: 350 images\n",
      "Class 8: 350 images\n",
      "Class 9: 350 images\n",
      "Class 10: 350 images\n",
      "Class 11: 350 images\n",
      "Class 12: 350 images\n",
      "Class 13: 350 images\n",
      "Class 14: 350 images\n",
      "Class 15: 350 images\n",
      "Class 16: 350 images\n",
      "Class 17: 350 images\n",
      "Class 18: 350 images\n",
      "Class 19: 350 images\n",
      "Class 20: 350 images\n",
      "Class 21: 350 images\n",
      "Class 22: 350 images\n",
      "Class 23: 350 images\n",
      "Class 24: 350 images\n",
      "Class 25: 350 images\n",
      "Class 26: 350 images\n",
      "Class 27: 350 images\n",
      "Class 28: 350 images\n",
      "Class 29: 350 images\n",
      "Class 30: 350 images\n",
      "Class 31: 350 images\n",
      "Class 32: 350 images\n",
      "Class 33: 350 images\n",
      "Class 34: 350 images\n",
      "Class 35: 350 images\n",
      "Class 36: 350 images\n",
      "Class 37: 350 images\n",
      "Class 38: 350 images\n",
      "Class 39: 350 images\n",
      "Class 40: 350 images\n",
      "Class 41: 350 images\n",
      "Class 42: 350 images\n",
      "Class 43: 350 images\n",
      "Class 44: 350 images\n",
      "Class 45: 350 images\n",
      "Class 46: 350 images\n",
      "Class 47: 350 images\n",
      "Class 48: 350 images\n",
      "Class 49: 350 images\n",
      "Class 50: 350 images\n",
      "Class 51: 350 images\n",
      "Class 52: 350 images\n",
      "Class 53: 350 images\n",
      "Class 54: 350 images\n",
      "Class 55: 350 images\n",
      "Class 56: 350 images\n",
      "Class 57: 350 images\n",
      "Class 58: 350 images\n",
      "Class 59: 350 images\n",
      "Class 60: 350 images\n",
      "Class 61: 350 images\n",
      "Class 62: 350 images\n",
      "Class 63: 350 images\n",
      "Class 64: 350 images\n",
      "Class 65: 350 images\n",
      "Class 66: 350 images\n",
      "Class 67: 350 images\n",
      "Class 68: 350 images\n",
      "Class 69: 350 images\n",
      "Class 70: 350 images\n",
      "Class 71: 350 images\n",
      "Class 72: 350 images\n",
      "Class 73: 350 images\n",
      "Class 74: 350 images\n",
      "Class 75: 350 images\n",
      "Class 76: 350 images\n",
      "Class 77: 350 images\n",
      "Class 78: 350 images\n",
      "Class 79: 350 images\n",
      "Class 80: 350 images\n",
      "Class 81: 350 images\n",
      "Class 82: 350 images\n",
      "Class 83: 350 images\n",
      "Class 84: 350 images\n",
      "Class 85: 350 images\n",
      "Class 86: 350 images\n",
      "Class 87: 350 images\n",
      "Class 88: 350 images\n",
      "Class 89: 350 images\n",
      "Class 90: 350 images\n",
      "Class 91: 350 images\n",
      "Class 92: 350 images\n",
      "Class 93: 350 images\n",
      "Class 94: 350 images\n",
      "Class 95: 350 images\n",
      "Class 96: 350 images\n",
      "Class 97: 350 images\n",
      "Class 98: 350 images\n",
      "Class 99: 350 images\n",
      "\n",
      "All classes have 1000 images?: False\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "train_file = \"val.txt\"\n",
    "\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "with open(train_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        path, label = line.strip().rsplit(\" \", 1)\n",
    "        class_counts[label] += 1\n",
    "\n",
    "# Print counts\n",
    "for label in sorted(class_counts.keys(), key=lambda x: int(x)):\n",
    "    print(f\"Class {label}: {class_counts[label]} images\")\n",
    "\n",
    "# Check if all equal to 1000\n",
    "all_ok = all(count == 1000 for count in class_counts.values())\n",
    "\n",
    "print(\"\\nAll classes have 1000 images?:\", all_ok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a1198-822c-43a3-85ff-8307100c593c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5332225-0839-43c8-ae93-8cc5e8002839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ce5e27-56ba-4932-86d0-59efd94e6fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(64,49,768).mean(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c79b106-9a48-48b0-b3b9-f0918d66f291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(64, 1).squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867bb02-9896-4a8f-8b80-8bc439e362d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (memomae)",
   "language": "python",
   "name": "memomae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
